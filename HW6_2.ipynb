{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfbe20fa-426a-4f89-b2d8-c01a91d0627c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-tiny-patch4-window7-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([100, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Pretrained Swin Models ===\n",
      "Loading model: microsoft/swin-tiny-patch4-window7-224\n",
      "Freezing backbone weights...\n",
      "Total Parameters: 27.60 M\n",
      "Trainable Parameters: 0.08 M\n",
      "\n",
      "--- Fine-tuning swin-tiny-patch4-window7-224 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 4.0444, Test Loss: 3.4833, Test Acc: 47.31%, Time: 153.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 3.0527, Test Loss: 2.6567, Test Acc: 58.63%, Time: 107.84s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 2.3741, Test Loss: 2.1184, Test Acc: 62.47%, Time: 108.22s\n",
      "Finished Training swin-tiny-patch4-window7-224. Best Test Accuracy: 62.47%\n",
      "Final Epoch Test Accuracy: 62.47%\n",
      "Loading model: microsoft/swin-small-patch4-window7-224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-small-patch4-window7-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([100, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing backbone weights...\n",
      "Total Parameters: 48.91 M\n",
      "Trainable Parameters: 0.08 M\n",
      "\n",
      "--- Fine-tuning swin-small-patch4-window7-224 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 3.9770, Test Loss: 3.3574, Test Acc: 53.54%, Time: 172.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 2.8896, Test Loss: 2.4638, Test Acc: 63.23%, Time: 172.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 2.1679, Test Loss: 1.9089, Test Acc: 66.97%, Time: 172.34s\n",
      "Finished Training swin-small-patch4-window7-224. Best Test Accuracy: 66.97%\n",
      "Final Epoch Test Accuracy: 66.97%\n",
      "\n",
      "--- Results Summary (Fine-tuning vs Scratch) ---\n",
      "                       Model Configuration Avg Epoch Time (s) Test Acc (%) @3 epochs\n",
      " swin-tiny-patch4-window7-224 (Fine-tuned)             123.29                  62.47\n",
      "swin-small-patch4-window7-224 (Fine-tuned)             172.40                  66.97\n",
      "    Swin-Tiny (From Scratch - Placeholder)                N/A                    N/A\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Fine-tuning pretrained Swin Transformers (Tiny and Small) on CIFAR-100\n",
    "and preparing for comparison with training from scratch. (Corrected)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import SwinForImageClassification, AutoImageProcessor\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm # For progress bars\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "# Models to fine-tune\n",
    "model_checkpoints = [\n",
    "    \"microsoft/swin-tiny-patch4-window7-224\",\n",
    "    \"microsoft/swin-small-patch4-window7-224\",\n",
    "]\n",
    "\n",
    "\n",
    "# Training Hyperparameters\n",
    "BATCH_SIZE = 32 # As requested\n",
    "EPOCHS = 3      # Fine-tune for 2-5 epochs (using 3 here, adjustable)\n",
    "LR = 2e-5       # As requested (AdamW usually uses smaller LR for fine-tuning)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_CLASSES = 100 # For CIFAR-100\n",
    "\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "\n",
    "# --- Data Loading and Preprocessing ---\n",
    "# Swin models often pretrained on 224x224 images. Resize CIFAR-100.\n",
    "processor = AutoImageProcessor.from_pretrained(model_checkpoints[0])\n",
    "image_mean = processor.image_mean\n",
    "image_std = processor.image_std\n",
    "size = processor.size[\"height\"] # Should be 224\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean=image_mean, std=image_std)\n",
    "_transform = transforms.Compose([\n",
    "        transforms.Resize((size, size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "\n",
    "# Apply transforms to CIFAR-100\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True if DEVICE=='cuda' else False)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True if DEVICE=='cuda' else False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Model Loading and Modification ---\n",
    "def load_and_prepare_model(checkpoint, num_labels, freeze_backbone=True):\n",
    "    print(f\"Loading model: {checkpoint}\")\n",
    "    model = SwinForImageClassification.from_pretrained(\n",
    "        checkpoint,\n",
    "        num_labels=num_labels,\n",
    "        ignore_mismatched_sizes=True, # Necessary because we are replacing the head\n",
    "    )\n",
    "\n",
    "\n",
    "    # Freeze backbone if required\n",
    "    if freeze_backbone:\n",
    "        print(\"Freezing backbone weights...\")\n",
    "        for param in model.swin.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Ensure the classifier head is trainable\n",
    "        for param in model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        print(\"Training entire model (backbone unfrozen)...\") # For scratch comparison later\n",
    "\n",
    "\n",
    "    # Print trainable parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total Parameters: {total_params/1e6:.2f} M\")\n",
    "    print(f\"Trainable Parameters: {trainable_params/1e6:.2f} M\")\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- Training and Evaluation Loop ---\n",
    "def train_model(model, model_name, trainloader, testloader, optimizer, epochs, device):\n",
    "    print(f\"\\n--- Fine-tuning {model_name} ---\")\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss() # Define loss function inside\n",
    "    results = {'train_loss': [], 'test_loss': [], 'test_acc': [], 'epoch_time': []}\n",
    "    best_acc = 0.0\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "        for batch in progress_bar:\n",
    "            # Assuming standard torchvision loader output (inputs, labels)\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            # Transformers models usually return a dictionary-like object\n",
    "            outputs = model(inputs)\n",
    "            logits = outputs.logits # Extract logits\n",
    "\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            # *** CORRECTED LINE BELOW ***\n",
    "            progress_bar.set_postfix({'loss': loss.item()}) # Pass the float directly\n",
    "\n",
    "\n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "        results['train_loss'].append(epoch_loss)\n",
    "\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in testloader:\n",
    "                inputs, labels = batch\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                logits = outputs.logits\n",
    "                loss = criterion(logits, labels)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = torch.max(logits.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "        epoch_test_loss = test_loss / len(testloader)\n",
    "        epoch_test_acc = 100 * correct / total\n",
    "        results['test_loss'].append(epoch_test_loss)\n",
    "        results['test_acc'].append(epoch_test_acc)\n",
    "\n",
    "\n",
    "        if epoch_test_acc > best_acc:\n",
    "             best_acc = epoch_test_acc\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "        results['epoch_time'].append(epoch_duration)\n",
    "\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {epoch_loss:.4f}, Test Loss: {epoch_test_loss:.4f}, Test Acc: {epoch_test_acc:.2f}%, Time: {epoch_duration:.2f}s\")\n",
    "\n",
    "\n",
    "    print(f\"Finished Training {model_name}. Best Test Accuracy: {best_acc:.2f}%\")\n",
    "    avg_epoch_time = sum(results['epoch_time']) / len(results['epoch_time']) if results['epoch_time'] else 0\n",
    "    final_acc = results['test_acc'][-1] if results['test_acc'] else 0 # Use final epoch accuracy for report\n",
    "    print(f\"Final Epoch Test Accuracy: {final_acc:.2f}%\")\n",
    "    return final_acc, avg_epoch_time # Return final accuracy and avg time\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "results_data = []\n",
    "\n",
    "\n",
    "print(\"\\n=== Processing Pretrained Swin Models ===\")\n",
    "for checkpoint in model_checkpoints:\n",
    "    model_name = checkpoint.split('/')[-1]\n",
    "    model = load_and_prepare_model(checkpoint, NUM_CLASSES, freeze_backbone=True)\n",
    "\n",
    "\n",
    "    # Define optimizer for fine-tuning (only optimizing the head)\n",
    "    # Use AdamW which is common for transformers\n",
    "    optimizer = optim.AdamW(model.classifier.parameters(), lr=LR)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    final_acc, avg_epoch_time = train_model(model, model_name, train_loader, test_loader, optimizer, EPOCHS, DEVICE)\n",
    "\n",
    "\n",
    "    results_data.append({\n",
    "        \"Model Configuration\": model_name + \" (Fine-tuned)\",\n",
    "        \"Avg Epoch Time (s)\": f\"{avg_epoch_time:.2f}\",\n",
    "        f\"Test Acc (%) @{EPOCHS} epochs\": f\"{final_acc:.2f}\"\n",
    "    })\n",
    "    del model # Free up memory\n",
    "    if DEVICE == 'cuda': torch.cuda.empty_cache() # Clear CUDA cache\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Placeholder for Scratch Model Comparison ---\n",
    "results_data.append({\n",
    "    \"Model Configuration\": \"Swin-Tiny (From Scratch - Placeholder)\",\n",
    "    \"Avg Epoch Time (s)\": \"N/A\", # Measure if implemented\n",
    "    f\"Test Acc (%) @{EPOCHS} epochs\": \"N/A\" # Get from scratch run\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Display Summary Table ---\n",
    "print(\"\\n--- Results Summary (Fine-tuning vs Scratch) ---\")\n",
    "results_df = pd.DataFrame(results_data)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3950d7-851e-4f04-bb8c-a7acbcb4db40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Jim1)",
   "language": "python",
   "name": "jim1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
